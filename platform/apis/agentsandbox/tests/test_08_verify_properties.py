#!/usr/bin/env python3
"""
Verify AgentSandboxService properties
Usage: pytest test_08_verify_properties.py [--tenant <name>] [--namespace <name>] [-v] [--cleanup]

Comprehensive property-based testing for AgentSandboxService
Validates all correctness properties defined in the design document
"""

import pytest
import subprocess
import os
import time
import random
import string
from typing import List


@pytest.fixture
def properties_test_config():
    """Provide properties test configuration"""
    return {
        "property_test_iterations": 3,  # Reduced for faster testing
        "test_claim_prefix": f"pbt-test-{int(time.time())}"
    }


@pytest.fixture
def cleanup_properties_claims(properties_test_config, tenant_config):
    """Cleanup all property test resources"""
    yield
    
    # Clean up all test claims with the prefix
    # try:
    #     result = subprocess.run([
    #         "kubectl", "get", "agentsandboxservice", "-n", tenant_config['namespace'],
    #         "-o", "jsonpath={.items[*].metadata.name}"
    #     ], capture_output=True, text=True, check=False)
        
    #     if result.returncode == 0 and result.stdout.strip():
    #         claim_names = result.stdout.strip().split()
    #         for claim_name in claim_names:
    #             if claim_name.startswith(properties_test_config['test_claim_prefix']):
    #                 subprocess.run([
    #                     "kubectl", "delete", "agentsandboxservice", claim_name,
    #                     "-n", tenant_config['namespace'], "--ignore-not-found=true"
    #                 ], capture_output=True, text=True, check=False)
    # except:
    #     pass


def generate_random_claim_spec(claim_name: str, namespace: str) -> str:
    """Generate random valid claim specification"""
    sizes = ["micro", "small", "medium", "large"]
    size = random.choice(sizes)
    
    return f"""apiVersion: platform.bizmatters.io/v1alpha1
kind: AgentSandboxService
metadata:
  name: {claim_name}
  namespace: {namespace}
spec:
  image: "busybox:latest"
  size: {size}
  nats:
    stream: "TEST_STREAM_{random.randint(1, 1000)}"
    consumer: "test-consumer-{random.randint(1, 1000)}"
  storageGB: {random.choice([5, 10, 20])}
"""


def test_validate_prerequisites(colors, kubectl_helper, tenant_config, test_counters, properties_test_config):
    """Validate prerequisites for property-based testing"""
    print("Starting AgentSandboxService property-based testing")
    print(f"Tenant: {tenant_config['tenant_name']}, Namespace: {tenant_config['namespace']}, Iterations: {properties_test_config['property_test_iterations']}")
    print(f"{colors.BLUE}[INFO] Validating prerequisites for property-based testing...{colors.NC}")
    
    # Check namespace exists
    try:
        kubectl_helper.kubectl_retry(["get", "namespace", tenant_config['namespace']])
    except Exception:
        print(f"{colors.RED}[ERROR] Namespace {tenant_config['namespace']} does not exist{colors.NC}")
        test_counters.errors += 1
        pytest.fail(f"Namespace {tenant_config['namespace']} does not exist")
    
    # Check AgentSandboxService XRD exists
    try:
        kubectl_helper.kubectl_retry(["get", "xrd", "xagentsandboxservices.platform.bizmatters.io"])
    except Exception:
        print(f"{colors.RED}[ERROR] AgentSandboxService XRD not found{colors.NC}")
        test_counters.errors += 1
        pytest.fail("AgentSandboxService XRD not found")
    
    # Check agent-sandbox controller is running
    try:
        result = kubectl_helper.kubectl_retry([
            "get", "pods", "-n", "agent-sandbox-system", 
            "-l", "app=agent-sandbox-controller"
        ])
        if "Running" not in result.stdout:
            print(f"{colors.RED}[ERROR] Agent-sandbox controller not running{colors.NC}")
            test_counters.errors += 1
            pytest.fail("Agent-sandbox controller not running")
    except Exception:
        print(f"{colors.RED}[ERROR] Could not check agent-sandbox controller{colors.NC}")
        test_counters.errors += 1
        pytest.fail("Could not check agent-sandbox controller")
    
    # Check aws-access-token secret exists
    try:
        kubectl_helper.kubectl_retry(["get", "secret", "aws-access-token", "-n", tenant_config['namespace']])
    except Exception:
        print(f"{colors.RED}[ERROR] aws-access-token secret not found in namespace {tenant_config['namespace']}{colors.NC}")
        test_counters.errors += 1
        pytest.fail("aws-access-token secret not found")
    
    print(f"{colors.BLUE}[INFO] Prerequisites validated successfully{colors.NC}")


def test_property_api_parity(colors, properties_test_config, tenant_config, test_counters, cleanup_properties_claims):
    """Property 1: API Parity Preservation"""
    print(f"{colors.BLUE}[PROPERTY] Testing Property 1: API Parity Preservation{colors.NC}")
    print(f"{colors.BLUE}[INFO] For any valid EventDrivenService claim specification, converting it to AgentSandboxService should succeed{colors.NC}")
    
    failures = 0
    
    for i in range(1, properties_test_config['property_test_iterations'] + 1):
        print(f"{colors.BLUE}[INFO] Iteration {i}/{properties_test_config['property_test_iterations']}{colors.NC}")
        
        # Generate random valid claim specification
        claim_name = f"{properties_test_config['test_claim_prefix']}-api-{i}"
        claim_spec = generate_random_claim_spec(claim_name, tenant_config['namespace'])
        
        # Create AgentSandboxService claim
        try:
            subprocess.run([
                "kubectl", "apply", "-f", "-"
            ], input=claim_spec, text=True, capture_output=True, check=True)
        except subprocess.CalledProcessError:
            print(f"{colors.RED}[ERROR] Failed to create AgentSandboxService claim (iteration {i}){colors.NC}")
            failures += 1
            continue
        
        # Wait for claim to be accepted by API server
        try:
            subprocess.run([
                "kubectl", "get", "agentsandboxservice", claim_name, "-n", tenant_config['namespace']
            ], capture_output=True, text=True, check=True)
        except subprocess.CalledProcessError:
            print(f"{colors.RED}[ERROR] AgentSandboxService claim not found after creation (iteration {i}){colors.NC}")
            failures += 1
            continue
        
        # Validate claim was processed (don't wait for full readiness)
        timeout = 30
        elapsed = 0
        processed = False
        
        while elapsed < timeout:
            try:
                result = subprocess.run([
                    "kubectl", "get", "agentsandboxservice", claim_name, "-n", tenant_config['namespace'],
                    "-o", "jsonpath={.status.conditions}"
                ], capture_output=True, text=True, check=True)
                conditions = result.stdout.strip()
                
                if conditions and conditions not in ["[]", "null"]:
                    processed = True
                    break
            except subprocess.CalledProcessError:
                pass
            
            time.sleep(2)
            elapsed += 2
        
        if not processed:
            print(f"{colors.RED}[ERROR] AgentSandboxService claim not processed within timeout (iteration {i}){colors.NC}")
            failures += 1
        
        # Clean up this iteration
        subprocess.run([
            "kubectl", "delete", "agentsandboxservice", claim_name, 
            "-n", tenant_config['namespace'], "--ignore-not-found=true"
        ], capture_output=True, text=True, check=False)
    
    if failures == 0:
        print(f"{colors.GREEN}[SUCCESS] Property 1 (API Parity Preservation): PASSED ({properties_test_config['property_test_iterations']}/{properties_test_config['property_test_iterations']}){colors.NC}")
    else:
        print(f"{colors.RED}[ERROR] Property 1 (API Parity Preservation): FAILED ({properties_test_config['property_test_iterations'] - failures}/{properties_test_config['property_test_iterations']}){colors.NC}")
        test_counters.errors += 1
        pytest.fail(f"Property 1 failed: {failures} out of {properties_test_config['property_test_iterations']} iterations failed")


def test_property_resource_provisioning(colors, properties_test_config, tenant_config, test_counters, cleanup_properties_claims):
    """Property 2: Resource Provisioning Completeness"""
    print(f"{colors.BLUE}[PROPERTY] Testing Property 2: Resource Provisioning Completeness{colors.NC}")
    print(f"{colors.BLUE}[INFO] For any AgentSandboxService claim, composition should generate exactly the expected managed resources{colors.NC}")
    
    failures = 0
    
    for i in range(1, properties_test_config['property_test_iterations'] + 1):
        print(f"{colors.BLUE}[INFO] Iteration {i}/{properties_test_config['property_test_iterations']}{colors.NC}")
        
        # Generate random claim
        claim_name = f"{properties_test_config['test_claim_prefix']}-res-{i}"
        claim_spec = generate_random_claim_spec(claim_name, tenant_config['namespace'])
        
        # Create claim
        try:
            subprocess.run([
                "kubectl", "apply", "-f", "-"
            ], input=claim_spec, text=True, capture_output=True, check=True)
        except subprocess.CalledProcessError:
            print(f"{colors.RED}[ERROR] Failed to create claim (iteration {i}){colors.NC}")
            failures += 1
            continue
        
        # Wait for resources to be provisioned (shorter timeout for property testing)
        timeout = 120
        elapsed = 0
        
        while elapsed < timeout:
            try:
                result = subprocess.run([
                    "kubectl", "get", "agentsandboxservice", claim_name, "-n", tenant_config['namespace'],
                    "-o", "jsonpath={.status.conditions[?(@.type==\"Ready\")].status}"
                ], capture_output=True, text=True, check=True)
                if "True" in result.stdout:
                    break
            except subprocess.CalledProcessError:
                pass
            
            time.sleep(5)
            elapsed += 5
        
        if elapsed >= timeout:
            print(f"{colors.YELLOW}[WARNING] Claim not ready within timeout, checking partial provisioning (iteration {i}){colors.NC}")
        
        # Validate expected resources exist
        expected_resources = ["sandboxtemplate", "sandboxwarmpool", "serviceaccount"]
        
        resource_failures = 0
        for resource_type in expected_resources:
            try:
                subprocess.run([
                    "kubectl", "get", resource_type, claim_name, "-n", tenant_config['namespace']
                ], capture_output=True, text=True, check=True)
            except subprocess.CalledProcessError:
                print(f"{colors.RED}[ERROR] Missing {resource_type} resource (iteration {i}){colors.NC}")
                resource_failures += 1
        
        if resource_failures > 0:
            failures += 1
        
        # Clean up
        subprocess.run([
            "kubectl", "delete", "agentsandboxservice", claim_name, 
            "-n", tenant_config['namespace'], "--ignore-not-found=true"
        ], capture_output=True, text=True, check=False)
    
    if failures == 0:
        print(f"{colors.GREEN}[SUCCESS] Property 2 (Resource Provisioning Completeness): PASSED ({properties_test_config['property_test_iterations']}/{properties_test_config['property_test_iterations']}){colors.NC}")
    else:
        print(f"{colors.RED}[ERROR] Property 2 (Resource Provisioning Completeness): FAILED ({properties_test_config['property_test_iterations'] - failures}/{properties_test_config['property_test_iterations']}){colors.NC}")
        test_counters.errors += 1
        pytest.fail(f"Property 2 failed: {failures} out of {properties_test_config['property_test_iterations']} iterations failed")


def test_property_workspace_persistence(colors, properties_test_config, tenant_config, test_counters, cleanup_properties_claims):
    """Property 3: Workspace Persistence Round-Trip"""
    print(f"{colors.BLUE}[PROPERTY] Testing Property 3: Workspace Persistence Round-Trip{colors.NC}")
    print(f"{colors.BLUE}[INFO] For any file written to /workspace, it should survive pod recreation{colors.NC}")
    
    failures = 0
    
    for i in range(1, properties_test_config['property_test_iterations'] + 1):
        print(f"{colors.BLUE}[INFO] Iteration {i}/{properties_test_config['property_test_iterations']}{colors.NC}")
        
        # Generate claim with persistent storage
        claim_name = f"{properties_test_config['test_claim_prefix']}-persist-{i}"
        claim_spec = generate_random_claim_spec(claim_name, tenant_config['namespace'])
        
        # Create claim
        try:
            subprocess.run([
                "kubectl", "apply", "-f", "-"
            ], input=claim_spec, text=True, capture_output=True, check=True)
        except subprocess.CalledProcessError:
            print(f"{colors.RED}[ERROR] Failed to create persistent claim (iteration {i}){colors.NC}")
            failures += 1
            continue
        
        # Wait for PVC to be created (infrastructure test)
        timeout = 60
        elapsed = 0
        pvc_created = False
        
        while elapsed < timeout:
            try:
                result = subprocess.run([
                    "kubectl", "get", "pvc", "-n", tenant_config['namespace'],
                    "-l", f"app.kubernetes.io/name={claim_name}"
                ], capture_output=True, text=True, check=True)
                if result.stdout.strip():
                    pvc_created = True
                    break
            except subprocess.CalledProcessError:
                pass
            
            time.sleep(2)
            elapsed += 2
        
        if not pvc_created:
            print(f"{colors.RED}[ERROR] PVC not created for persistent storage (iteration {i}){colors.NC}")
            failures += 1
        else:
            print(f"{colors.BLUE}[INFO] PVC created successfully for persistence test (iteration {i}){colors.NC}")
        
        # Clean up
        subprocess.run([
            "kubectl", "delete", "agentsandboxservice", claim_name, 
            "-n", tenant_config['namespace'], "--ignore-not-found=true"
        ], capture_output=True, text=True, check=False)
    
    if failures == 0:
        print(f"{colors.GREEN}[SUCCESS] Property 3 (Workspace Persistence Round-Trip): PASSED ({properties_test_config['property_test_iterations']}/{properties_test_config['property_test_iterations']}){colors.NC}")
    else:
        print(f"{colors.RED}[ERROR] Property 3 (Workspace Persistence Round-Trip): FAILED ({properties_test_config['property_test_iterations'] - failures}/{properties_test_config['property_test_iterations']}){colors.NC}")
        test_counters.errors += 1
        pytest.fail(f"Property 3 failed: {failures} out of {properties_test_config['property_test_iterations']} iterations failed")


def test_property_keda_scaling(colors, properties_test_config, tenant_config, test_counters, cleanup_properties_claims):
    """Property 4: KEDA Scaling Responsiveness"""
    print(f"{colors.BLUE}[PROPERTY] Testing Property 4: KEDA Scaling Responsiveness{colors.NC}")
    print(f"{colors.BLUE}[INFO] For any AgentSandboxService with NATS config, KEDA ScaledObject should be created and configured{colors.NC}")
    
    failures = 0
    
    for i in range(1, properties_test_config['property_test_iterations'] + 1):
        print(f"{colors.BLUE}[INFO] Iteration {i}/{properties_test_config['property_test_iterations']}{colors.NC}")
        
        # Generate claim with NATS configuration
        claim_name = f"{properties_test_config['test_claim_prefix']}-keda-{i}"
        claim_spec = generate_random_claim_spec(claim_name, tenant_config['namespace'])
        
        # Create claim
        try:
            subprocess.run([
                "kubectl", "apply", "-f", "-"
            ], input=claim_spec, text=True, capture_output=True, check=True)
        except subprocess.CalledProcessError:
            print(f"{colors.RED}[ERROR] Failed to create NATS claim (iteration {i}){colors.NC}")
            failures += 1
            continue
        
        # Wait for ScaledObject to be created
        timeout = 60
        elapsed = 0
        scaledobject_created = False
        
        while elapsed < timeout:
            try:
                subprocess.run([
                    "kubectl", "get", "scaledobject", claim_name, "-n", tenant_config['namespace']
                ], capture_output=True, text=True, check=True)
                scaledobject_created = True
                break
            except subprocess.CalledProcessError:
                pass
            
            time.sleep(2)
            elapsed += 2
        
        if not scaledobject_created:
            print(f"{colors.RED}[ERROR] ScaledObject not created (iteration {i}){colors.NC}")
            failures += 1
        else:
            print(f"{colors.BLUE}[INFO] ScaledObject created successfully (iteration {i}){colors.NC}")
        
        # Clean up
        subprocess.run([
            "kubectl", "delete", "agentsandboxservice", claim_name, 
            "-n", tenant_config['namespace'], "--ignore-not-found=true"
        ], capture_output=True, text=True, check=False)
    
    if failures == 0:
        print(f"{colors.GREEN}[SUCCESS] Property 4 (KEDA Scaling Responsiveness): PASSED ({properties_test_config['property_test_iterations']}/{properties_test_config['property_test_iterations']}){colors.NC}")
    else:
        print(f"{colors.RED}[ERROR] Property 4 (KEDA Scaling Responsiveness): FAILED ({properties_test_config['property_test_iterations'] - failures}/{properties_test_config['property_test_iterations']}){colors.NC}")
        test_counters.errors += 1
        pytest.fail(f"Property 4 failed: {failures} out of {properties_test_config['property_test_iterations']} iterations failed")


def test_summary(colors, test_counters):
    """Print validation summary"""
    print(f"{colors.GREEN}[SUCCESS] âœ… All correctness properties validated successfully!{colors.NC}")
    print(f"{colors.GREEN}[SUCCESS] AgentSandboxService implementation meets all design requirements{colors.NC}")
    
    if test_counters.errors == 0:
        print(f"{colors.GREEN}[SUCCESS] All property-based validation checks passed!{colors.NC}")
    else:
        pytest.fail(f"Property-based validation has {test_counters.errors} error(s)")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])